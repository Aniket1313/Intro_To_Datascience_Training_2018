---
title: "capstone - statistics"
input: "bank_full_clean.csv"
---

### Introduction
The bank data set displays data collected for a marketing campaign aimed at getting customers to subscribe to term deposits. The data has already been cleaned up so the next step would be to analyze the data through exploratory data analysis and see if there are any conclusions that can be drawn.


### Step 1  Internal structure and cleanup of the data
The first step to analyzing the data would be to look at the internal structure of the data object. By loading the clean data into R and 
using the str and summary function. We can see that the clients range from age 20 to 80 with an annual balance between -8019 and 102127,
other numerical data covers contact frequency, last contact date and contact duration.

The most immediate outliers we have in the dataset shows up in age. So by looking at the distribution of age, we can decide whether or not we'd like to remove ages that are niche to our analysis. After creating a datatable that caculates the frequencies of the ages, we can delete any age that covers less than 1% of the data. Which narrows down our age distribution to between ages 25 and 60.

```R
##load your dataset into the R environment
library(readr)
bank_full_clean <- read_csv("C:/Users/Alan/Desktop/bank_full_clean.csv")

##look at the attributes of the dataset
str(bank_full_clean)
View(summary(bank_full_clean))
age<-data.frame((ftable(bank_full_clean$age)))
age$percent<-age$Freq/sum(age$Freq)*100
bank <- bank_full_clean[bank_full_clean$age <= 60 & bank_full_clean$age >= 25, ] 
library(moments)
skewness(bank$age)
kurtosis(bank$age)
```

| age | freq | percent |
|-----|------|---------|
| 20  | 50   | 0.11    |
| 25  | 510  | 1.16    |
| 33  | 1922 | 4.40    |

Another part of the data that might contain outliers are the negative annual balance holders, logically speaking, users with negative annual balance holders are unlikely to open up a term deposit account. However, just to be sure, we can use frequency tables to determine whether or not this is true. By filtering out the negative balance holders we can see that they make up 8.5% of clients after we've removed our age outliers that users that opened a term deposit make up less than 0.5% of clients. Thus we can consider removing these users from our data set since it would be unlikely that they would affect the outcome of our analysis too much

```R
##subset the data with negative annual balance and observer frequencies
bk_f<-bank[bank$annual_balance<0,c(6,17)]
table(bk_f$outcome_term_deposit)
bank_m<-bank[bank$annual_balance>0,-which(names(bank) %in% c("last_contact_month","last_contact_day","past_days"))]
```

| no  | yes  | 
|-----|------|
|3366 | 201  |
|0.08 |0.0048|

Finally,last_contact_month, last_contact_day and past_days should be removed to avoid confusion regarding numerical values for the analysis.



### Step 2 Analyzing and Visualizing the data
Moving on, we can sort all the different columns into categorical/numerical/binary data. Starting with categorical and binary data, we can generate a few histograms to see the relationship between age distribution along with other variables. We can easily discover that very few clients have default credit, so eventually we can remove that column from our dataset. Based on the histogram, everything else seems fairly normal.

```R
#Age histogram and removing outliers
library(ggplot2)
ggplot(bank_m, aes(x=age)) + geom_histogram(binwidth = 5)
plotseries<-function(yvar){
ggplot(bank_m, aes(x=age,fill = factor(yvar))) + geom_histogram(binwidth = 5)
}
lapply(bank_m[,c(2,3,4,5,7,8,9,13,14)], plotseries)
table(bank$default_credit)
bank_m<-bank_m[,-which(names(bank_m)%in%c("default_credit"))]
```

<b>default_credit</b>

| no  | yes  | 
|-----|------|
|41018| 767  |
|0.981|0.0183|


Proceeding to numerical data, we can use bubble charts or scatterplots to understand the numerical values of our dataset. After creating these charts, we can see that within charts annual_balance, duration and previous_contact_times all contain extreme values. We can verify whether these values are true or false by simply using the table chart again, but this time with value limits of balance over 80000, duration over 4000 and previous contact times over 100. After we've confirmed that those values are in the single digits, we can proceed to eliminate them from our dataset. 

```R
##questionable bubble chart
bubbleseries<-function(zvar){
  ggplot(bank_m,aes(x=age, y=zvar, size = zvar, color = zvar)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
}
lapply(bank_m[,c(5,9,10,11)], bubbleseries)

table(bank_m$annual_balance>80000)
table(bank_m$duration>4000)
table(bank_m$previous_contact_times>100)

bank_m<-bank_m[bank_m$previous_contact_times<100,]
bank_m<-bank_m[bank_m$annual_balance<80000,]
```


### Step 3 Correlations and Chi-squares
To measure the relations between numerical and categorical variables, we proceed split our datasets into two matrixes, one including numerical value and the other containing only categorical values. To see if the numerical values have any relationship between each other we use a correlation table.
We can see none of the values exceeds 0.1, which means that there isn't a strong correlation between these values.

```R
#Correlation Matrix
bank_n<-bank_m[,c(1,5,9,10,11)]
cor(bank_n)

```

| age annual_balance  |   duration |contact_times| previous_contact_times |
|---------------------|------------|-------------|---------|
| age                 |    1.00000000 |   0.083356651 | -0.030597602|   0.050363918 |          -0.027508176 |
| annual_balance      |    0.08335665 |   1.000000000 |  0.015113375|  -0.006504731 |           0.009739325 |
| duration            |   -0.03059760 |   0.015113375 |  1.000000000|  -0.048924942 |          -0.008585207 |
| contact_times       |    0.05036392 |  -0.006504731 | -0.048924942|   1.000000000 |          -0.010718597 |
| previous_contact_times| -0.02750818 |   0.009739325 | -0.008585207|  -0.010718597 |           1.000000000 |



On the other hand, with categorical data, we can implement the Chi-square matrix and display all P-values between entries, if the
p-values we obtain objects the null, it could mean that there are strong differences between the categories and their objects.

```R
#create two dimensional tab
bank.tab<-table(bank_m$prev_outcome,bank_m$outcome_term_deposit)

#row marginal
margin.table(bank.tab,1)

#column marginal
margin.table(bank.tab,2) 

#cell %
round(prop.table(bank.tab),2)

#row %
round(prop.table(bank.tab,1),2) 

#column %
round(prop.table(bank.tab,2),2) 

#Chi-squared test
chisq.test(bank.tab)

#Categorical Data
bank_c<-bank_m[,c(2,3,4,6,7,8,12,13)]

#Chi-square Matrix
chisqmatrix <- function(x) {
  names = colnames(x);  num = length(names)
  m = matrix(nrow=num,ncol=num,dimnames=list(names,names))
  for (i in 1:(num-1)) {
    for (j in (i+1):num) {
      m[i,j] = chisq.test(x[[i]],x[[j]],)$p.value
    }
  }
  return (m)
}
mat = chisqmatrix(bank_c)
View(mat)

```


| Chi-square Matrix    | job | marital | education | housing_loan | personal_loan | contact_type | prev_outcome | outcome_term_deposit |
|----------------------|-----|---------|-----------|--------------|---------------|--------------|--------------|----------------------|
| job                  | NA  | 0.00    | 0.00      | 0.00         | 0.00          | 0.00         | 0.00         | 0.00                 |
| marital              | NA  | NA      | 0.00      | 0.00         | 0.00          | 0.00         | 0.00         | 0.00                 |
| education            | NA  | NA      | NA        | 0.00         | 0.00          | 0.00         | 0.00         | 0.00                 |
| housing_loan         | NA  | NA      | NA        | NA           | 0.00          | 0.00         | 0.00         | 0.00                 |
| personal_loan        | NA  | NA      | NA        | NA           | NA            | 0.14         | 0.00         | 0.00                 |
| contact_type         | NA  | NA      | NA        | NA           | NA            | NA           | 0.00         | 0.00                 |
| prev_outcome         | NA  | NA      | NA        | NA           | NA            | NA           | NA           | 0.00                 |
| outcome_term_deposit | NA  | NA      | NA        | NA           | NA            | NA           | NA           | NA                   |


Assuming that our Alpha Level is 0.05, we can see that only Contact_type and Personal_Loan seems to be unrelated, all other categorical data combinations have a p-value that rejects the null. Meaning most categorical data do have some affect on the outcome_term_desposit.

### Interval - Converting data into factors

For our dataset to be able to fit within a machine learning model it is import to factorize all categorical features which include all dummy variables.

```R
#convert all categorical data into factors
cols <- c("job","marital","education","contact_type","prev_outcome","dummy_default_credit","dummy_housing_loan","dummy_personal_loan","dummy_outcome_term_deposit") 

bank_m[cols] <- lapply(bank_m[cols], factor)

bank_adj<-bank_m[,c(1,2,3,4,5,8,9,10,11,12,14,15,16,17)]

#remove NA values
bank_adj<-na.omit(bank_adj)

##note it would be wise to put all na values in a seperate dataframe to make sure no important data that contained other existing features were removed. 
```
By deploying the code above we are able to further cleanup the data for it to fit in machine learning models.


### Step 4 Build a Classification Tree
Since the data we have is a mixture of categorical and numerical data and the resulting outcome of the data is binary. The obvious model to fit the data with is a Tree Based Model. In our case, we've built a classification tree using the code below.
```R
#split data into training sets and test sets
if (!require(caTools)) install.packages('caTools')
library(caTools)
set.seed(28)
split <- sample.split(bank_adj$dummy_outcome_term_deposit, SplitRatio = 0.7)
train <- subset(bank_adj,split == TRUE)
test <- subset(bank_adj, split == FALSE)
if (!require(rpart)) install.packages('rpart')
if (!require(rpart.plot)) install.packages('rpart.plot')
#build a basic tree diagram using the train data set
library(rpart)
library(rpart.plot)
banktree <- rpart(dummy_outcome_term_deposit ~ age + job + marital + education + annual_balance + contact_type + duration + contact_times + previous_contact_times + prev_outcome + dummy_default_credit + dummy_housing_loan + dummy_personal_loan, data = train, method = 'class', control = rpart.control(minbucket=25))
prp(banktree)
```
![alt text](https://github.com/arclightspanner/Springboard-Project/blob/master/Datastory/Tree%20Diagram.JPG)

We can see that draw a few conclusions based on the tree that R generated above:

1.The tree is solely based on duration and previous contact outcomes, which is an indication that other features did not stand out or show significance compared to these two features. 

2.When the contact duration exceeds 14 minutes, the likihood for success increases.

3.If contact duration is below that, then the results would be based on the outcome of previous campaign, if the previous campaign was successful then the consumer would be morely to open up a term deposit if not then the consumer would less likely open up a term deposit.

To further test the accuracy of the data we would move this model from our training data to our test data and measure the accuracy of that set. In addition, we would generate an ROC curve to determine how good our prediction was. 

```R
#verify accuracy with test data
bankpredict = predict(banktree, newdata = test, type="class")
table(test$dummy_outcome_term_deposit,bankpredict)
accuracy = (9060+428)/(9060+218+788+428)
print(accuracy)

#generate an ROC curve for the model
if (!require(ROCR)) install.packages('ROCR')
library(ROCR)
predictROC <- predict(banktree, newdata = test)
predictROC
pred <- prediction(predictROC[,2],test$dummy_outcome_term_deposit)
perf <- performance(pred,"tpr","fpr")
plot(perf)
```
![alt text](https://github.com/arclightspanner/Springboard-Project/blob/master/Datastory/ROC%20Curve.JPG?raw=true)

We can see that our model is able to generate an accuracy rate of 90.41% and a left leaning ROC curve which indicates a reasonable accuracy of the prediction.

Although our classification model already has an accuracy rate of 90.41%, it might be interesting to see if a Random Forest Model would be able to increase that accuracy rate higher.

```R
#Deploy Random Forest
if (!require(randomForest)) install.packages('randomForest')
library(randomForest)
bankForest <- randomForest(dummy_outcome_term_deposit ~ age + job + marital + education + annual_balance + contact_type + duration + contact_times + previous_contact_times + prev_outcome + dummy_default_credit + dummy_housing_loan + dummy_personal_loan, data = train, nodesize = 25, ntree = 200)
predictForest <- predict(bankForest, newdata = test)
table(test$dummy_outcome_term_deposit,predictForest)
accuracy = (9067+386)/(9067+386+211+830)
print(accuracy)
```
The accuracy we received from the Random Forest Model is 90.08% which is a bit lower than the classification model, so it would be recommended that we use the classification model to make future predictions.

### Step 5 Researching Consumer Features
From the classification model diagram in step 4, we can see that prev_outcome and duration are the main features determining the decisions made. But what if we wanted to see if age/job/marital status/education could help us determine potential clients in the future. Surely demographics would play a key feature in our modeling if we didn't have previous campaign results and contact info. 
So in this step we removed duration and prev_out and only include variables highlighting personal demographic information.
```R
bank_fr<-bank_adj[,c(1,2,3,4,5,11,12,13,14)]
set.seed(48)
split <- sample.split(bank_fr$dummy_outcome_term_deposit, SplitRatio = 0.7)
train <- subset(bank_fr,split == TRUE)
test <- subset(bank_fr, split == FALSE)
banktree_fr <- rpart(dummy_outcome_term_deposit ~ age + job + marital + education + annual_balance + dummy_default_credit + dummy_housing_loan + dummy_personal_loan, data = train, method = 'class', control = rpart.control(minbucket=25))
prp(banktree_fr)
```
The code above only generated a "0" node, which means that the majority of predictions predicted that no matter what the features were, they would not sign up for a term deposit any way or the other. So instead of using a classification model, we proceed to generate a random forest

```R
bankForest <- randomForest(dummy_outcome_term_deposit ~ age + job + marital + education + annual_balance + dummy_default_credit + dummy_housing_loan + dummy_personal_loan, data = train, nodesize = 25, ntree = 200)
table(test$dummy_outcome_term_deposit,predictForest)
accuracy = (8827+146)/(1070+8827+451+146)
print(accuracy)
```
The random forest generated an accuracy of 85.5%, however, since we have around 200 trees, it's hard to determine what feature affected the models decision.In this scenario, we deployed a partial dependence plot to most features in order to understand what affected the model the most.

```{R}
###Use Partial Dependence Plot to figure out what is going on within the randomforest model
if (!require(pdp)) install.packages('pdp')

library(pdp)
library(ggplot2)

#plot variable age
par.bank <- partial(bankForest, pred.var = c("age"), chull = TRUE)
plot.age <- autoplot(par.bank, contour = TRUE)

#plot variable job
par.bank <- partial(bankForest, pred.var = c("job"), chull = TRUE)
plot.job <- autoplot(par.bank, contour = TRUE)

#plot variable marital
par.bank <- partial(bankForest, pred.var = c("marital"), chull = TRUE)
plot.marital <- autoplot(par.bank, contour = TRUE)

#plot variable education
par.bank <- partial(bankForest, pred.var = c("education"), chull = TRUE)
plot.education <- autoplot(par.bank, contour = TRUE)

#plot variable annual balance
par.bank <- partial(bankForest, pred.var = c("annual_balance"), chull = TRUE)
plot.annual_balance <- autoplot(par.bank, contour = TRUE)

grid.arrange(plot.age,plot.job,plot.marital,plot.education,plot.annual_balance)
```

![alt text](https://github.com/arclightspanner/Springboard-Project/blob/master/Datastory/PDP%20Results.JPG?raw=true)

Unfortunately, Partial Dependence Plot shows that nearly all major consumer attributes positively contributed to the final decision making of the random forest. Thus it is difficult to determine what actually contributes to the results of the forrest.

### Conclusion

By researching the data and deploying both statistics and machine learning models, we can conclude that the success of this particular campaign was determined by the contact duration and the success of the previous campaign. From a marketing standpoint, it makes sense that consumers that are willing to listen to the seller for long periods of time and is already a customer from the beginning is more likely to accept similar services from the same organization. This data and the classification tree we've built shows just that. While we are also able to generate a high accuracy machine learning model without data containing the two important features mentioned above, we are unable to determine what actually matters in terms of consumer demographics in relation to campaign success. However, this model can still be used to predict future campaign success if marketers want to target specific groups of consumers. The only issue would be the lack of transparency and understanding of how the model works internally. 
